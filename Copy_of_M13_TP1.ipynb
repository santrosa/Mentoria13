{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "UtZBXCxdajr1",
   "metadata": {
    "id": "UtZBXCxdajr1"
   },
   "source": [
    "**Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones**\n",
    "\n",
    "---\n",
    "\n",
    "Mentoría #13 - Cómo hacer un Clasificador de Pliegos todoterreno (y de otros tipos de textos) usando NLP\n",
    "\n",
    "---\n",
    "Integrantes Grupo [1|2]:\n",
    "*   Bruce Wayne: bruce.w@wayne-entreprises.com\n",
    "*   Alfred Pennyworth: alfred@msn.com\n",
    "*   Richard Grayson: robin_132@gmail.com\n",
    "---\n",
    "\n",
    "Edición 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86f66f",
   "metadata": {
    "id": "7b86f66f"
   },
   "source": [
    "# Introducción\n",
    "\n",
    "En esta Mentoría, trabajaremos con un conjunto de datos que comprende aproximadamente 100.000 pliegos y licitaciones de diversos organismos nacionales, tanto públicos como privados. Estos datos se obtuvieron de un sistema/servicio diseñado para monitorear oportunidades de negocios, capturar la información en una base de datos, normalizarla y, posteriormente, clasificarla para informar a los usuarios según sus áreas de interés. Los usuarios de este sistema reciben alertas automáticas cada vez que se publica una oportunidad comercial que coincide con su perfil.\n",
    "\n",
    "## Desafío\n",
    "\n",
    "Como parte del proceso de clasificación, los pliegos se etiquetan utilizando principalmente reglas estáticas, como palabras clave, lo cual deja margen para optimizaciones. El título de cada pliego y principalmente la descripción de los objetos que se están licitando son campos de tipo texto y escritos por personas, por lo que naturalmente presentan ambigüedades y características propias del lenguaje que llevan a que un enfoque rígido y estático de clasificación, como el actual, resulte limitado y poco eficiente.\n",
    "\n",
    "El Desafío es utilizar las técnicas de Aprendizaje Automático, logrando así un \"Clasificador\" que utilice técnicas de Procesamiento de Lenguaje Natural (NLP) para clasificar de manera más eficiente en qué rubro o categoría se encuentra un pliego, basándose en su texto descriptivo y otros campos relacionados.\n",
    "\n",
    "## Interés General\n",
    "\n",
    "Más allá de la aplicación específica en este conjunto de datos, este problema, al estar vinculado al Procesamiento de Lenguaje Natural (PLN) y la clasificación, tiene la ventaja de poder ser utilizado posteriormente para otros tipos de contenido. De esta manera, el clasificador desarrollado podría aplicarse para categorizar libros, noticias, textos, tweets, publicaciones, artículos, etc.\n",
    "\n",
    "## Descripción del dataset\n",
    "\n",
    "A continuación se enumeran las diferentes variables del dataset, así como una breve descripción de su significado:\n",
    "\n",
    "- **id**: Clave única y primaria autoincremental de la tabla;\n",
    "- **cargado**: Fecha de carga del pliego;\n",
    "- **idexterno**: Id del pliego en la fuente;\n",
    "- **referencia**: Campo auxiliar obtenido de la fuente;\n",
    "- **objeto**: Campo principal, descripción del producto o servicio objeto de la licitación;\n",
    "- **rubro**: Campo de categorización disponible en la fuente. No siempre está disponible;\n",
    "- **agencia**: Empresa o Ente que lanza la licitación;\n",
    "- **apertura**: Fecha de apertura del pliego (vencimiento para presentarse al pliego);\n",
    "- **subrubro**: Subcategoría del pliego (también obtenido desde la fuente);\n",
    "- **pais**: País donde se lanza la licitación;\n",
    "- **observaciones**: Campo auxiliar donde se guardan datos extra que puede variar según la fuente;\n",
    "- **monto**: Monto del pliego, no siempre está publicado;\n",
    "- **divisaSimboloISO**: Moneda en la que se especifica el pliego;\n",
    "- **visible**: campo binario que determina si el pliego va a ser visualizado por el sistema (True/False);\n",
    "- **categoría**: Tipo de pliego, categorización entre diversos tipos de pliegos (Compra Directa, Licitación Simple, Subasta, etc.);\n",
    "- **fuente**: Fuente de donde se obtuvo la licitación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaImQfxeYd8Z",
   "metadata": {
    "id": "eaImQfxeYd8Z"
   },
   "source": [
    "# Trabajo Práctico #1\n",
    "\n",
    "Como primer trabajo práctico se requiere hacer un análisis exploratorio del dataset, analizando distribuciones, dispersión de las variables, naturaleza de los datos alojados en cada variable, etc. Es una primera aproximación a los datos, por lo que, como todo trabajo de exploración, requiere principalmente de técnicas de visualización, agrupación y lectura de las distintas variables.\n",
    "\n",
    "A continuación se enumeran los ejercicios propuestos como guía:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EXILjx8pd2zb",
   "metadata": {
    "id": "EXILjx8pd2zb"
   },
   "source": [
    "## Ejercicio 1: Descripción\n",
    "\n",
    "Hacer una descripción propia del dataset a modo de resumen, resaltando las variables que se consideran más importantes.\n",
    "\n",
    "Describir las principales variables según las características de los datos, por ejemplo, explorar la distribución de los valores, la característica de los mismos, explorar el conjunto para evidenciar si existen valores faltantes.\n",
    "\n",
    "De preferencia, utilizar visualizaciones en esta etapa de exploración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07xb2chXeBjx",
   "metadata": {
    "id": "07xb2chXeBjx"
   },
   "source": [
    "## Ejercicio 2: Exploración\n",
    "\n",
    "Analizar ahora con mayor detalle las variables importantes dentro del conjunto:\n",
    "\n",
    "*   Hay variables numéricas?\n",
    "*   Son del tipo contínuo o discreta\n",
    "*   Hay variables categóricas?\n",
    "*   Hay variables \"derivadas\" de otras variables\n",
    "*   En las variables de tipo texto, es homogénea la longitud de los datos?\n",
    "*   Hay registros con mayor longitud que otros?\n",
    "*   Representará esto un problema a tratar más adelante?\n",
    "*   Existen desbalances en la distribución o son los datos homogéneos?\n",
    "*   Existen datos faltantes?\n",
    "\n",
    "Nuevamente, utilizar las preguntas descriptas como guía para la exploración y hacer gráficas y visualizaciones como forma práctica de evidenciar lo observado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rpbtM0BGkWQ4",
   "metadata": {
    "id": "rpbtM0BGkWQ4"
   },
   "source": [
    "## Ejercicio 3: Análisis\n",
    "\n",
    "A partir de los datos y de la exploración realizada, qué podemos anticipar en relación a las variables *rubro* y *subrubro*?\n",
    "\n",
    "Están siempre presentes? Representan algún tipo de desbalanceo?\n",
    "\n",
    "Existen pliegos con más de una categorización en la fuente de origen? Qué distribución hay en ese caso?\n",
    "\n",
    "Nota: Aquí ya nos topamos con una de las problemáticas del dataset. Es esta categorización en origen \"confiable\"? Qué posturas podemos tomar frente a estas etiquetas originales?\n",
    "\n",
    "Describir en forma de texto la postura del Grupo respecto a estas variables y a posibles estrategias para abordarlas en adelante. Este será un factor muy importante cuando comencemos a preparar el dataset para alimentar los modelos de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b56da7",
   "metadata": {
    "id": "14b56da7"
   },
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XbgaB6JqjjWy",
   "metadata": {
    "id": "XbgaB6JqjjWy"
   },
   "outputs": [],
   "source": [
    "# Link al dataset: https://drive.google.com/file/d/1jo9cZNHAPpsTosW-2JA4CLo4SaFCHfIs/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BMcav1-2aaJP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "BMcav1-2aaJP",
    "outputId": "752b64bc-aa66-4fb1-c0dd-5a387d8fd961"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./Mentoria_Dataset_0.csv\" , encoding='latin-1')\n",
    "\n",
    "df.head()\n",
    "\n",
    "#print(len(df))\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(6, 5))\n",
    "msno.bar(df, sort=\"ascending\", fontsize=12, color=\"tab:green\", ax=axs)\n",
    "#axs.set_ylim(0.8, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
